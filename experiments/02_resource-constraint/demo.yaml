apiVersion: v1
kind: Pod
metadata:
  name: demo
  namespace: default
  labels:
    experiment: demo
spec:
  schedulerName: hami-scheduler
  restartPolicy: Never

  containers:
  - name: demo-container
    image: docker.cnb.cool/lcjd1024/os/mypython
    command: ["python", "run.py"]
    # command: ["sleep", "36000"]
    volumeMounts:
    - name: cache-volume
      mountPath: /root/.cache/huggingface
    - name: data-volume
      mountPath: /app/data
    - name: code-volume
      mountPath: /app/run.py
    resources:
      requests:
        cpu: 1
        memory: 1Gi
        nvidia.com/gpu: 1.0
        nvidia.com/gpumem: 6000
      limits:
        cpu: 1
        memory: 1Gi
        nvidia.com/gpu: 1.0
        nvidia.com/gpumem: 6000
    env:
    - name: NVIDIA_VISIBLE_DEVICES
      value: all
    - name: HF_HOME
      value: /root/.cache/huggingface

  volumes:
  - name: cache-volume
    hostPath: 
      path: /home/zhangjingzhou/.cache/huggingface
      type: Directory
  - name: data-volume
    hostPath: 
      path: /home/zhangjingzhou/tool-planning/Project-TOMAS/experiments/02_resource-constraint/data
      type: Directory
  - name: code-volume
    hostPath: 
      path: /home/zhangjingzhou/tool-planning/Project-TOMAS/experiments/02_resource-constraint/inference.py
      type: File