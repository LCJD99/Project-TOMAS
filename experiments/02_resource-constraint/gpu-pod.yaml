apiVersion: v1
kind: Pod
metadata:
  name: gpu-pid
  namespace: default
spec:
  schedulerName: hami-scheduler
  containers:
  - name: cuda-container
    image: docker.cnb.cool/lcjd1024/os
    args: ["bash", "-c", "sleep 86400"]
    resources:
      limits:
        nvidia.com/gpu: 1 # 请求1个vGPU
        nvidia.com/gpumem: 3000
    env:
    - name: NVIDIA_VISIBLE_DEVICES
      value: all
    - name: NVIDIA_DRIVER_CAPABILITIES
      value: all
